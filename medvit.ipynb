{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11833612,"sourceType":"datasetVersion","datasetId":7434358}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T06:28:19.249164Z","iopub.execute_input":"2025-05-17T06:28:19.249403Z","iopub.status.idle":"2025-05-17T06:28:27.539448Z","shell.execute_reply.started":"2025-05-17T06:28:19.249386Z","shell.execute_reply":"2025-05-17T06:28:27.538736Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install timm\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport torch\nfrom torch import nn\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import classification_report\nimport timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:37:28.079046Z","iopub.execute_input":"2025-05-20T05:37:28.079271Z","iopub.status.idle":"2025-05-20T05:38:50.860518Z","shell.execute_reply.started":"2025-05-20T05:37:28.079246Z","shell.execute_reply":"2025-05-20T05:38:50.859722Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:39:02.333460Z","iopub.execute_input":"2025-05-20T05:39:02.333785Z","iopub.status.idle":"2025-05-20T05:39:05.305408Z","shell.execute_reply.started":"2025-05-20T05:39:02.333753Z","shell.execute_reply":"2025-05-20T05:39:05.304715Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Get the GitHub token from Kaggle environment\ntoken = os.environ.get(\"GITHUB_TOKEN\")\n\n# Format the clone URL with the token\nrepo_url = f\"https://{token}@github.com/Omid-Nejati/MedViT.git\"\n\n# Clone the repository\n!git clone {repo_url}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:39:08.694694Z","iopub.execute_input":"2025-05-20T05:39:08.695374Z","iopub.status.idle":"2025-05-20T05:39:09.536378Z","shell.execute_reply.started":"2025-05-20T05:39:08.695340Z","shell.execute_reply":"2025-05-20T05:39:09.535681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/MedViT\n!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:39:13.350366Z","iopub.execute_input":"2025-05-20T05:39:13.351055Z","iopub.status.idle":"2025-05-20T05:39:25.793529Z","shell.execute_reply.started":"2025-05-20T05:39:13.351023Z","shell.execute_reply":"2025-05-20T05:39:25.792773Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:39:37.073616Z","iopub.execute_input":"2025-05-20T05:39:37.074011Z","iopub.status.idle":"2025-05-20T05:39:37.218200Z","shell.execute_reply.started":"2025-05-20T05:39:37.073980Z","shell.execute_reply":"2025-05-20T05:39:37.217223Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nfrom torch.utils.data import random_split, DataLoader\n\n# Define transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])\n\n# Load full dataset\ndataset = ImageFolder('/kaggle/input/adni-3-class/ADNI_3_class', transform=transform)\n\n# Split into train/test\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:39:40.469221Z","iopub.execute_input":"2025-05-20T05:39:40.469876Z","iopub.status.idle":"2025-05-20T05:39:45.845847Z","shell.execute_reply.started":"2025-05-20T05:39:40.469841Z","shell.execute_reply":"2025-05-20T05:39:45.845076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install timm\n!pip install einops","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:39:49.404847Z","iopub.execute_input":"2025-05-20T05:39:49.405147Z","iopub.status.idle":"2025-05-20T05:39:55.691356Z","shell.execute_reply.started":"2025-05-20T05:39:49.405127Z","shell.execute_reply":"2025-05-20T05:39:55.690504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from MedViT import MedViT_small as tiny","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:40:00.393642Z","iopub.execute_input":"2025-05-20T05:40:00.393963Z","iopub.status.idle":"2025-05-20T05:40:00.431428Z","shell.execute_reply.started":"2025-05-20T05:40:00.393932Z","shell.execute_reply":"2025-05-20T05:40:00.430715Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = tiny()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:40:02.546999Z","iopub.execute_input":"2025-05-20T05:40:02.547774Z","iopub.status.idle":"2025-05-20T05:40:03.135690Z","shell.execute_reply.started":"2025-05-20T05:40:02.547747Z","shell.execute_reply":"2025-05-20T05:40:03.134890Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = tiny().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:42:22.684423Z","iopub.execute_input":"2025-05-20T05:42:22.685377Z","iopub.status.idle":"2025-05-20T05:42:23.545778Z","shell.execute_reply.started":"2025-05-20T05:42:22.685350Z","shell.execute_reply":"2025-05-20T05:42:23.545181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchsummary import summary\nmodel = model.to(device)\nsummary(model, (3, 224, 224))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:42:26.764065Z","iopub.execute_input":"2025-05-20T05:42:26.764336Z","iopub.status.idle":"2025-05-20T05:42:27.364552Z","shell.execute_reply.started":"2025-05-20T05:42:26.764316Z","shell.execute_reply":"2025-05-20T05:42:27.363701Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def print_shapes(name):\n    def hook(model, input, output):\n        print(f\"{name}:\")\n        print(f\"  Input shape: {input[0].shape}\")\n        print(f\"  Output shape: {output.shape}\")\n    return hook\n\n# Register hooks to layers you care about (Conv2d, Linear, etc.)\nfor name, layer in model.named_modules():\n    if isinstance(layer, (torch.nn.Conv2d, torch.nn.Linear, torch.nn.LayerNorm)):\n        layer.register_forward_hook(print_shapes(name))\n\n# Feed a dummy input\ndummy_input = torch.randn(1, 3, 224, 224).to(device)\nmodel.eval()  # Important to disable dropout/batchnorm randomness\nwith torch.no_grad():\n    _ = model(dummy_input)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:44:01.425376Z","iopub.execute_input":"2025-05-20T05:44:01.426268Z","iopub.status.idle":"2025-05-20T05:44:01.529187Z","shell.execute_reply.started":"2025-05-20T05:44:01.426233Z","shell.execute_reply":"2025-05-20T05:44:01.528343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import label_binarize\nimport numpy as np\nimport seaborn as sns\n\n# Setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n# Tracking variables\ntrain_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\n\n# Early stopping\nbest_acc = 0\npatience = 5\ncounter = 0\n\n# Store for plots\nall_preds, all_labels = [], []\nall_probs, all_logits = [], []\nall_features = []\n\n# Training loop\nfor epoch in range(10):\n    model.train()\n    train_loss, correct, total = 0, 0, 0\n\n    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/10\", leave=False)\n    for inputs, labels in loop:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n        loop.set_postfix(loss=loss.item())\n\n    avg_train_loss = train_loss / len(train_loader)\n    train_acc = correct / total\n    train_losses.append(avg_train_loss)\n    train_accuracies.append(train_acc)\n\n    # Validation\n    model.eval()\n    val_loss, correct, total = 0, 0, 0\n\n    temp_preds, temp_labels = [], []\n    temp_probs, temp_logits, temp_features = [], [], []\n\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n            temp_preds.extend(preds.cpu().numpy())\n            temp_labels.extend(labels.cpu().numpy())\n            probs = F.softmax(outputs, dim=1)\n            temp_probs.extend(probs.cpu().numpy())\n            temp_logits.extend(outputs.cpu().numpy())\n\n            # Feature extraction for t-SNE\n            if hasattr(model, 'forward_features'):\n                features = model.forward_features(inputs)\n            else:\n                features = inputs  # fallback\n\n            temp_features.extend(features.cpu().numpy())\n\n    avg_val_loss = val_loss / len(val_loader)\n    val_acc = correct / total\n    val_losses.append(avg_val_loss)\n    val_accuracies.append(val_acc)\n\n    # Save predictions and features from final epoch only\n    if epoch == 19 or (val_acc > best_acc):\n        all_preds = temp_preds\n        all_labels = temp_labels\n        all_probs = temp_probs\n        all_logits = temp_logits\n        all_features = temp_features\n\n    print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Train Acc={train_acc:.4f}, \"\n          f\"Val Loss={avg_val_loss:.4f}, Val Acc={val_acc:.4f}\")\n\n    # Early stopping logic\n    if val_acc < best_acc + 0.03:\n        counter += 1\n        if counter >= patience:\n            print(f\"ðŸ›‘ Early stopping at epoch {epoch+1}\")\n            break\n    else:\n        best_acc = val_acc\n        counter = 0\n\n# Save model\ntorch.save(model.state_dict(), \"medvit_model.pth\")\nprint(\"âœ… Model saved as 'medvit_model.pth'\")\n\n# === Evaluation Metrics ===\ncf = confusion_matrix(all_labels, all_preds)\nreport = classification_report(all_labels, all_preds, output_dict=True)\nacc = report['accuracy']\nprecision = np.mean([report[str(i)]['precision'] for i in range(len(cf))])\nrecall = np.mean([report[str(i)]['recall'] for i in range(len(cf))])\nspecificity = np.mean([\n    (cf.sum() - (cf[i].sum() + cf[:, i].sum() - cf[i, i])) / \n    (cf.sum() - cf[:, i].sum()) \n    for i in range(len(cf))\n])\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(all_labels, all_preds))\nprint(f\"Accuracy: {acc:.4f}\")\nprint(f\"Precision (macro): {precision:.4f}\")\nprint(f\"Recall (macro): {recall:.4f}\")\nprint(f\"Specificity (macro): {specificity:.4f}\")\n\n# === Confusion Matrix ===\nplt.figure(figsize=(6,5))\nsns.heatmap(cf, annot=True, fmt=\"d\", cmap=\"Blues\")\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.show()\n\n# === Accuracy & Loss Curves ===\nepochs_range = range(1, len(train_losses) + 1)\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, train_losses, label=\"Train Loss\")\nplt.plot(epochs_range, val_losses, label=\"Val Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss Curve\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, train_accuracies, label=\"Train Acc\")\nplt.plot(epochs_range, val_accuracies, label=\"Val Acc\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy Curve\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# === Ready for Additional Plots ===\n# All data for t-SNE, ROC, and PR curves are now stored in:\n# - all_labels\n# - all_preds\n# - all_probs\n# - all_logits\n# - all_features\n\n# Example of use:\n# tsne = TSNE().fit_transform(np.array(all_features))\n# fpr, tpr, _ = roc_curve(...)\n# precision, recall, _ = precision_recall_curve(...)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T06:30:18.596161Z","iopub.execute_input":"2025-05-17T06:30:18.596400Z","iopub.status.idle":"2025-05-17T06:43:55.580758Z","shell.execute_reply.started":"2025-05-17T06:30:18.596383Z","shell.execute_reply":"2025-05-17T06:43:55.579965Z"}},"outputs":[],"execution_count":null}]}